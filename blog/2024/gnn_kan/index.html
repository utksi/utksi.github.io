<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> E(3) - equivariant GNN with Learnable Activation Functions on Edges | Utkarsh Singh </title> <meta name="author" content="Utkarsh Singh"> <meta name="description" content="Some ideas about KAN-based GNNs beyond just stacking layers"> <meta name="keywords" content="physics, preovskite, optical, MLP, neural-network, NN, DFT, ab-initio"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="/assets/img/absorption2.png?d6e628c0dd411656b06d775fc45b63a7"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://utksi.github.io/blog/2024/gnn_kan/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Utkarsh</span> Singh </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">E(3) - equivariant GNN with Learnable Activation Functions on Edges</h1> <p class="post-meta"> Created in April 21, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> machine-learning</a>   <a href="/blog/tag/neural-network"> <i class="fa-solid fa-hashtag fa-sm"></i> neural-network</a>   <a href="/blog/tag/gnn"> <i class="fa-solid fa-hashtag fa-sm"></i> GNN</a>   <a href="/blog/tag/nn"> <i class="fa-solid fa-hashtag fa-sm"></i> NN</a>   ·   <a href="/blog/category/worklog"> <i class="fa-solid fa-tag fa-sm"></i> worklog</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <ul> <li>KANs proposed by <a href="https://arxiv.org/abs/2404.19756" rel="external nofollow noopener" target="_blank">Liu et al.</a>.</li> <li>See <a href="https://github.com/GistNoesis/FourierKAN" rel="external nofollow noopener" target="_blank">Fourier-KAN</a> implementation, replaces splines with fourier coefficients.</li> </ul> <h2 id="general-message-passing-neural-network-mpnn">General Message Passing Neural Network (MPNN)</h2> <ol> <li> <p><strong>Input Node and Edge Features</strong>:</p> <ul> <li>Nodes: \(\mathbf{x}_i\) (node features)</li> <li>Edges: \(\mathbf{e}_{ij}\) (edge features)</li> </ul> </li> <li> <p><strong>Message Passing Layer</strong> (per layer):</p> <p>a. <strong>Edge Feature Transformation</strong>:</p> \[\mathbf{e}'_{ij} = f_e(\mathbf{e}_{ij})\] <p>where \(f_e\) is a transformation function applied to edge features.</p> <p>b. <strong>Message Computation</strong>:</p> \[\mathbf{m}_{ij} = f_m(\mathbf{x}_i, \mathbf{x}_j, \mathbf{e}'_{ij})\] <p>where \(f_m\) computes messages using node features \(\mathbf{x_i} ,\ \mathbf{x_j}\), and transformed edge features \(\mathbf{e}'_{ij}\).</p> <p>c. <strong>Message Aggregation</strong>:</p> \[\mathbf{m}_i = \sum_{j \in \mathcal{N}(i)} \mathbf{m}_{ij}\] <p>where \(\mathcal{N}(i)\) denotes the set of neighbors of node \(i\).</p> <p>d. <strong>Node Feature Update</strong>:</p> \[\mathbf{x}'_i = f_n(\mathbf{x}_i, \mathbf{m}_i)\] <p>where \(f_n\) updates node features using the aggregated messages \(\mathbf{m}_i\).</p> </li> <li> <p><strong>Output Node and Edge Features</strong>:</p> <ul> <li>Nodes: \(\mathbf{x}'_i\) (updated node features)</li> <li>Edges: \(\mathbf{e}'_{ij}\) (updated edge features)</li> </ul> </li> </ol> <h2 id="e3-equivariant-gnn-with-learnable-activation-functions-on-edges">E3-Equivariant GNN with Learnable Activation Functions on Edges</h2> <ol> <li> <p><strong>Input Node and Edge Features</strong>:</p> <ul> <li>Nodes: \(\mathbf{x}_i\) (node features)</li> <li>Edges: \(\mathbf{e}_{ij}\) (edge features)</li> </ul> </li> <li> <p><strong>Learnable Edge Feature Transformation</strong>:</p> <ul> <li> <p><strong>Fourier-based Edge Transformation</strong>:</p> \[\mathbf{e}'_{ij} = \text{FourierTransform}(\mathbf{e}_{ij})\] <p>where the Fourier transformation is applied to edge features. Specifically, the transformation is defined as:</p> \[\mathbf{e}'_{ij} = \sum_{k=1}^{K} a_{ij,k} \cos(k \mathbf{e}_{ij}) + b_{ij,k} \sin(k \mathbf{e}_{ij})\] <p>Here, \(a_{ij,k}\) and \(b_{ij,k}\) are learnable parameters, and \(K\) is the number of Fourier terms.</p> </li> </ul> </li> <li> <p><strong>Message Passing and Aggregation</strong>:</p> <p>a. <strong>Message Computation</strong>:</p> \[\mathbf{m}_{ij} = \mathbf{e}'_{ij} \odot \mathbf{x}_j\] <p>where \(\odot\) denotes element-wise multiplication, combining the transformed edge features \(\mathbf{e}'_{ij}\) with the neighboring node features \(\mathbf{x}_j\).</p> <p>b. <strong>Message Aggregation</strong>:</p> \[\mathbf{m}_i = \sum_{j \in \mathcal{N}(i)} \mathbf{m}_{ij}\] <p>c. <strong>Simple Node Feature Transformation</strong>:</p> \[\mathbf{x}'_i = \mathbf{W} (\mathbf{x}_i + \mathbf{m}_i) + \mathbf{b}\] <p>where \(\mathbf{W}\) is a learnable weight matrix and \(\mathbf{b}\) is a bias vector.</p> </li> <li> <p><strong>Output Node and Edge Features</strong>:</p> <ul> <li>Nodes: \(\mathbf{x}'_i\) (updated node features)</li> <li>Edges: \(\mathbf{e}'_{ij}\) (updated edge features)</li> </ul> </li> </ol> <h2 id="full-implementation">Full Implementation</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="n">torch_scatter</span> <span class="kn">import</span> <span class="n">scatter_add</span>
<span class="kn">from</span> <span class="n">torch_geometric.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="n">torch_geometric.datasets</span> <span class="kn">import</span> <span class="n">QM9</span>
<span class="kn">from</span> <span class="n">torch_geometric.transforms</span> <span class="kn">import</span> <span class="n">Distance</span>
<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">MessagePassing</span>
<span class="kn">from</span> <span class="n">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="n">e3nn</span> <span class="kn">import</span> <span class="n">o3</span>
<span class="kn">from</span> <span class="n">e3nn.nn</span> <span class="kn">import</span> <span class="n">Gate</span><span class="p">,</span> <span class="n">FullyConnectedNet</span>


<span class="k">class</span> <span class="nc">LearnableActivationEdge</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Class to define learnable activation functions on edges using Fourier series.
    Inspired by Kolmogorov-Arnold Networks (KANs) to capture complex, non-linear transformations on edge features.
    </span><span class="sh">"""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">inputdim</span><span class="p">,</span> <span class="n">outdim</span><span class="p">,</span> <span class="n">num_terms</span><span class="p">,</span> <span class="n">addbias</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Initialize the LearnableActivationEdge module.

        Args:
            inputdim (int): Dimension of input edge features.
            outdim (int): Dimension of output edge features.
            num_terms (int): Number of Fourier terms.
            addbias (bool): Whether to add a bias term. Default is True.
        </span><span class="sh">"""</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">LearnableActivationEdge</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>

        <span class="n">self</span><span class="p">.</span><span class="n">num_terms</span> <span class="o">=</span> <span class="n">num_terms</span>
        <span class="n">self</span><span class="p">.</span><span class="n">addbias</span> <span class="o">=</span> <span class="n">addbias</span>
        <span class="n">self</span><span class="p">.</span><span class="n">inputdim</span> <span class="o">=</span> <span class="n">inputdim</span>
        <span class="n">self</span><span class="p">.</span><span class="n">outdim</span> <span class="o">=</span> <span class="n">outdim</span>

        <span class="c1"># Initialize learnable Fourier coefficients
</span>        <span class="n">self</span><span class="p">.</span><span class="n">fouriercoeffs</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span>
            <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">outdim</span><span class="p">,</span> <span class="n">inputdim</span><span class="p">,</span> <span class="n">num_terms</span><span class="p">)</span> <span class="o">/</span>
            <span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">inputdim</span><span class="p">))</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">num_terms</span><span class="p">)))</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">addbias</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">outdim</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">edge_attr</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Forward pass to apply learnable activation functions on edge attributes.

        Args:
            edge_attr (Tensor): Edge attributes of shape (..., inputdim).

        Returns:
            Tensor: Transformed edge attributes of shape (..., outdim).
        </span><span class="sh">"""</span>
        <span class="n">xshp</span> <span class="o">=</span> <span class="n">edge_attr</span><span class="p">.</span><span class="n">shape</span>
        <span class="n">outshape</span> <span class="o">=</span> <span class="n">xshp</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">outdim</span><span class="p">,)</span>
        <span class="n">edge_attr</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">edge_attr</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">inputdim</span><span class="p">))</span>

        <span class="c1"># Generate Fourier terms
</span>        <span class="n">k</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">num_terms</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">edge_attr</span><span class="p">.</span><span class="n">device</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">num_terms</span><span class="p">)</span>
        <span class="n">xrshp</span> <span class="o">=</span> <span class="n">edge_attr</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Compute cosine and sine components
</span>        <span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cos</span><span class="p">(</span><span class="n">k</span> <span class="o">*</span> <span class="n">xrshp</span><span class="p">)</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="n">k</span> <span class="o">*</span> <span class="n">xrshp</span><span class="p">)</span>

        <span class="c1"># Apply learnable Fourier coefficients
</span>        <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">c</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">fouriercoeffs</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">y</span> <span class="o">+=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">s</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">fouriercoeffs</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="c1"># Add bias if applicable
</span>        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">addbias</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">+=</span> <span class="n">self</span><span class="p">.</span><span class="n">bias</span>

        <span class="c1"># Reshape to original edge attribute shape
</span>        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="n">outshape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>


<span class="k">class</span> <span class="nc">E3EquivariantGNN</span><span class="p">(</span><span class="n">MessagePassing</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    E(3)-Equivariant Graph Neural Network (GNN) that focuses on learnable activation functions on edges.
    </span><span class="sh">"""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">num_terms</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Initialize the E3EquivariantGNN module.

        Args:
            in_features (int): Dimension of input node features.
            out_features (int): Dimension of output node features.
            hidden_dim (int): Dimension of hidden layers.
            num_layers (int): Number of layers in the network.
            num_terms (int): Number of Fourier terms for learnable activation functions.
        </span><span class="sh">"""</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">E3EquivariantGNN</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">(</span><span class="n">aggr</span><span class="o">=</span><span class="sh">'</span><span class="s">add</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>

        <span class="c1"># Define the input and output irreps (representations)
</span>        <span class="n">self</span><span class="p">.</span><span class="n">input_irrep</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="n">Irreps</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="n">lmax</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Example irreps, adjust as needed
</span>        <span class="n">self</span><span class="p">.</span><span class="n">output_irrep</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nc">Irreps</span><span class="p">([(</span><span class="n">out_features</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))])</span>  <span class="c1"># Scalar output
</span>
        <span class="c1"># Define the hidden irreps
</span>        <span class="n">hidden_irreps</span> <span class="o">=</span> <span class="p">[</span><span class="n">o3</span><span class="p">.</span><span class="n">Irreps</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="n">lmax</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)]</span>  <span class="c1"># Adjust as needed
</span>
        <span class="c1"># Create the equivariant layers and learnable activation functions on edges
</span>        <span class="n">self</span><span class="p">.</span><span class="n">fourier_layers</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">([</span>
            <span class="nc">LearnableActivationEdge</span><span class="p">(</span><span class="n">in_features</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">num_terms</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)</span>
        <span class="p">])</span>
        <span class="n">self</span><span class="p">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">([</span>
            <span class="nc">Gate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">input_irrep</span><span class="p">,</span> <span class="n">hidden_irreps</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">num_terms</span><span class="p">),</span>
            <span class="o">*</span><span class="p">[</span><span class="nc">Gate</span><span class="p">(</span><span class="n">hidden_irreps</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">hidden_irreps</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">num_terms</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)],</span>
            <span class="nc">Gate</span><span class="p">(</span><span class="n">hidden_irreps</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">self</span><span class="p">.</span><span class="n">output_irrep</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">num_terms</span><span class="p">)</span>
        <span class="p">])</span>

        <span class="c1"># Output layer
</span>        <span class="n">self</span><span class="p">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">edge_attr</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Forward pass to propagate node features through the GNN.

        Args:
            x (Tensor): Node features of shape (num_nodes, in_features).
            edge_index (Tensor): Edge indices of shape (2, num_edges).
            edge_attr (Tensor): Edge attributes of shape (num_edges, edge_dim).

        Returns:
            Tensor: Output node features of shape (num_nodes, out_features).
        </span><span class="sh">"""</span>
        <span class="n">row</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="n">edge_index</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">num_layers</span><span class="p">):</span>
            <span class="c1"># Transform edge features with Fourier series
</span>            <span class="n">fourier_messages</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">fourier_layers</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">edge_attr</span><span class="p">)</span>

            <span class="c1"># Apply equivariant transformations to node features
</span>            <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="n">fourier_messages</span><span class="p">)</span>

            <span class="c1"># Compute messages
</span>            <span class="n">m_ij</span> <span class="o">=</span> <span class="n">fourier_messages</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">row</span><span class="p">]</span>

            <span class="c1"># Aggregate messages
</span>            <span class="n">m_i</span> <span class="o">=</span> <span class="nf">scatter_add</span><span class="p">(</span><span class="n">m_ij</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim_size</span><span class="o">=</span><span class="n">x</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

            <span class="c1"># Update node features
</span>            <span class="n">x</span> <span class="o">=</span> <span class="n">m_i</span>

        <span class="c1"># Apply the final linear layer
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">output_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="c1"># Load and prepare the QM9 dataset
</span><span class="n">dataset</span> <span class="o">=</span> <span class="nc">QM9</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="sh">'</span><span class="s">data/QM9</span><span class="sh">'</span><span class="p">)</span>
<span class="n">dataset</span><span class="p">.</span><span class="n">transform</span> <span class="o">=</span> <span class="nc">Distance</span><span class="p">(</span><span class="n">norm</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># Split dataset into training, validation, and test sets
</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:</span><span class="mi">110000</span><span class="p">]</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">110000</span><span class="p">:</span><span class="mi">120000</span><span class="p">]</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">120000</span><span class="p">:]</span>

<span class="c1"># Data loaders for training, validation, and test sets
</span><span class="n">train_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># Define the loss function and optimizer
</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">MSELoss</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">E3EquivariantGNN</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">num_terms</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Perform a single training step.

    Args:
        model (nn.Module): The neural network model.
        optimizer (Optimizer): The optimizer.
        criterion (Loss): The loss function.
        data (Data): The input data batch.

    Returns:
        float: The loss value.
    </span><span class="sh">"""</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_attr</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">)</span>
    <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>


<span class="c1"># Training loop
</span><span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">train_loss</span> <span class="o">+=</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
    <span class="n">train_loss</span> <span class="o">/=</span> <span class="nf">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>

    <span class="n">val_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_attr</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">)</span>
            <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
    <span class="n">val_loss</span> <span class="o">/=</span> <span class="nf">len</span><span class="p">(</span><span class="n">val_loader</span><span class="p">)</span>

    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Epoch </span><span class="si">{</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s">, Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">, Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <h2 id="detailed-explanation-of-mathematical-formulations">Detailed Explanation of Mathematical Formulations</h2> <h3 id="learnable-edge-feature-transformation">Learnable Edge Feature Transformation</h3> <p>For each edge \((i, j)\) with feature \(\mathbf{e}_{ij}\):</p> \[\mathbf{e}'_{ij} = \sum_{k=1}^{K} a_{ij,k} \cos(k \mathbf{e}_{ij}) + b_{ij,k} \sin(k \mathbf{e}_{ij})\] <p>where \(a_{ij,k}\) and \(b_{ij,k}\) are learnable parameters, and \(K\) is the number of terms.</p> <h3 id="message-computation">Message Computation</h3> <p>For each edge \((i, j)\):</p> \[\mathbf{m}_{ij} = \mathbf{e}'_{ij} \odot \mathbf{x}_j\] <p>where \(\odot\) denotes element-wise multiplication.</p> <h3 id="message-aggregation">Message Aggregation</h3> <p>For each node \(i\):</p> \[\mathbf{m}_i = \sum_{j \in \mathcal{N}(i)} \mathbf{m}_{ij}\] <p>where \(\mathcal{N}(i)\) denotes the set of neighbors of node \(i\).</p> <h3 id="node-feature-update">Node Feature Update</h3> <p>For each node \(i\):</p> \[\mathbf{x}'_i = \mathbf{W} (\mathbf{x}_i + \mathbf{m}_i) + \mathbf{b}\] <p>where \(\mathbf{W}\) is a learnable weight matrix and \(\mathbf{b}\) is a bias vector.</p> <h2 id="summary">Summary</h2> <p>This implementation combines the learnable activation functions on edges with E(3) equivariant transformations on node features. The detailed mathematical formulations provided in the comments explain each step of the process, making it suitable for a physicist audience familiar with these concepts.</p> <p>..#Idea #TODO: KANs for learnable edge activations in MACE - to have it as an option. Train on the same set.</p> </div> </article> </div> </div> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Utkarsh Singh. Last updated: January 16, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>