---
layout: post
title: "Cooperative Graph Neural Networks"
date: 2024-05-01 07:18
description: "Some crucial ideas from Finklestein et al.'s work on Cooperative GNNs"
tags: machine-learning-potential neural-network
categories: worklog
giscus_comments: false
related_posts: false
#toc: true
---

## Cooperative Graph Neural Networks (Co-GNNs)

- Proposed by [Finkelstein et al.](https://arxiv.org/abs/2310.01267)

### **Framework Overview**

Co-GNNs introduce a novel, flexible message-passing mechanism where each node in the graph dynamically selects from the actions: `listen`, `broadcast`, `listen and broadcast`, or `isolate`. This is facilitated by two cooperating networks:

1. **Action Network $\pi$**: Determines the optimal action for each node.
2. **Environment Network \( \eta \)**: Updates the node states based on the chosen actions.

## **Mathematical Formulation**

1. **Action Selection (Action Network \( \pi \))**:

   - For each node \(v\), the action network predicts a probability distribution \(p^{(\ell)}_v\) over the actions `{S, L, B, I}` at layer \( \ell \):

   \[ p^{(\ell)}_v = \pi \left( h^{(\ell)}_v, \{ h^{(\ell)}_u \mid u \in N_v \} \right) \]

   - Actions are sampled using the Straight-through Gumbel-softmax estimator.

2. **State Update (Environment Network \(\eta\))**:

   - The environment network updates the node states based on the selected actions:

   \[
   h^{(\ell+1)}_v =
   \begin{cases}
   \eta^{(\ell)} \left( h^{(\ell)}_v, \{ \} \right) & \text{if } a^{(\ell)}_v = \text{I or B} \\
   \eta^{(\ell)} \left( h^{(\ell)}_v, \{ h^{(\ell)}_u \mid u \in N_v, a^{(\ell)}_u = \text{S or B} \} \right) & \text{if } a^{(\ell)}_v = \text{L or S}
   \end{cases}
   \]

3. **Layer-wise Update**:
   - A Co-GNN layer involves predicting actions, sampling them, and updating node states.
   - Repeated for \(L\) layers to obtain final node representations \(h^{(L)}_v\).

### **Environment Network \(\eta\) Details**

The environment network updates node states using a message-passing scheme based on the selected actions. Letâ€™s consider the standard GCN layer and how it adapts to Co-GNN concepts:

1. **Message Aggregation**:

   - For each node \(v\), aggregate messages from its neighbors \(u\) that are broadcasting or using the standard action:
     \[
     m_v^{(\ell)} = \sum_{u \in N_v, a_u^{(\ell)} = \text{S or B}} h_u^{(\ell)}
     \]

2. **Node Update**:
   - The node updates its state based on the aggregated messages and its current state:
     \[
     h_v^{(\ell+1)} = \sigma \left( W^{(\ell)}_s h_v^{(\ell)} + W^{(\ell)}_n m_v^{(\ell)} \right)
     \]

### **Properties and Benefits**

- **Task-specific**: Nodes learn to focus on relevant neighbors based on the task.
- **Directed**: Edges can become directed, influencing directional information flow.
- **Dynamic and Feature-based**: Adapt to changing graph structures and node features.
- **Asynchronous Updates**: Nodes can be updated independently.
- **Expressive Power**: More expressive than traditional GNNs, capable of handling long-range dependencies and reducing over-squashing and over-smoothing.

### **Example Implementation**

Consider a GCN (Graph Convolutional Network) adapted with Co-GNN concepts:

1. **GCN Layer (Traditional)**:

   \[
   h^{(\ell+1)}_v = \sigma \left( W^{(\ell)}_s h^{(\ell)}_v + W^{(\ell)}_n \sum_{u \in N_v} h^{(\ell)}_u \right)
   \]

2. **Co-GNN Layer**:

   - **Action Network**: Predicts action probabilities for each node.

   \[
   p^{(\ell)}_v = \text{Softmax} \left( W_a h^{(\ell)}_v + b_a \right)
   \]

   - **Action Sampling**: Gumbel-softmax to select actions:
     \[
     a^{(\ell)}_v \sim \text{Gumbel-Softmax}(p^{(\ell)}_v)
     \]
   - **State Update (Environment Network)**:

   \[
   h^{(\ell+1)}_v =
   \begin{cases}
   \sigma \left( W^{(\ell)}_s h^{(\ell)}_v \right) & \text{if } a^{(\ell)}_v = \text{I or B} \\
   \sigma \left( W^{(\ell)}_s h^{(\ell)}_v + W^{(\ell)}_n \sum_{u \in N_v, a^{(\ell)}_u = \text{S or B}} h^{(\ell)}_u \right) & \text{if } a^{(\ell)}_v = \text{L or S}
   \end{cases}
   \]

## Conclusion

Co-GNNs represent a significant advancement in GNN architectures, offering a dynamic and adaptive message-passing framework that improves the handling of complex graph structures and long-range dependencies. The introduction of the Action Network and Environment Network provides a more flexible and task-specific approach to node state updates, leading to superior performance on various graph-related tasks.

For further details, refer to the [manuscript](https://arxiv.org/abs/2310.01267).